# backend/app/ai_advisor/rag/arabic_text_fixer.py
import fitz
import re
import logging
import os
import chardet
from typing import List, Dict, Any
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class ArabicTextFix:
    original: str
    fixed: str
    confidence: float
    method: str

class ArabicTextFixer:
    """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…Ø´ÙˆÙ‡ Ù…Ù† PDF"""
    
    def __init__(self):
        self.arabic_patterns = {
            'Ø§Ù„Ù…Ø§Ø¯Ø©': ['ïº”ï¯¿ï»¤ïº³ïº®ï»ŸØ§', 'ïº”ï¯¿ï»¤ïº³ïº®ï»ŸØ§', 'ï»¢ïº³ïº®ï»ŸØ§'],
            'Ù…Ø§Ø¯Ø©': ['ïº“ïºªï³Œïº', 'ïº“ïºªï³Œïº'],
            'Ø§Ù„Ø¨Ø§Ø¨': ['ïºïºïº’ï»Ÿïº', 'ïºïºïº’ï»Ÿïº'],
            'Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†': ['ï»¥ï»®ï»§ïºï»˜ï»Ÿïº', 'ï»¥ï»®ï»§ïºï»—'],
            'Ø§Ù„Ø¹Ù…Ù„': ['ï»ï»¤ï»Œï»Ÿïº', 'ï»ï»¤ï»Œï»Ÿïº'],
            'Ø§Ù„Ø¹Ø§Ù…Ù„': ['ï»ï»¤ï»Œï»Ÿïº', 'ï»ï»¤ï»Œï»Ÿïº']
        }
    
    def fix_arabic_text(self, text: str) -> ArabicTextFix:
        """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„Ù…Ø´ÙˆÙ‡"""
        if not text:
            return ArabicTextFix("", "", 0.0, "empty")
        
        methods_tried = []
        
        # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 1: Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙƒ ØªØ´ÙÙŠØ± Unicode
        try:
            fixed_unicode = self._fix_unicode_encoding(text)
            methods_tried.append(("unicode", fixed_unicode))
        except Exception as e:
            logger.debug(f"ÙØ´Ù„ Ø¥ØµÙ„Ø§Ø­ Unicode: {e}")
        
        # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 2: Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
        try:
            fixed_patterns = self._fix_known_patterns(text)
            methods_tried.append(("patterns", fixed_patterns))
        except Exception as e:
            logger.debug(f"ÙØ´Ù„ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {e}")
        
        # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© 3: ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ±Ù…ÙŠØ²
        try:
            fixed_encoding = self._fix_encoding(text)
            methods_tried.append(("encoding", fixed_encoding))
        except Exception as e:
            logger.debug(f"ÙØ´Ù„ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØªØ±Ù…ÙŠØ²: {e}")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
        best_fix = ""
        best_method = ""
        best_confidence = 0.0
        
        for method_name, fixed_text in methods_tried:
            if fixed_text:
                confidence = self._calculate_confidence(fixed_text)
                if confidence > best_confidence:
                    best_fix = fixed_text
                    best_method = method_name
                    best_confidence = confidence
        
        return ArabicTextFix(
            original=text[:200] + "..." if len(text) > 200 else text,
            fixed=best_fix,
            confidence=best_confidence,
            method=best_method
        )
    
    def _fix_unicode_encoding(self, text: str) -> str:
        """Ø¥ØµÙ„Ø§Ø­ ØªØ±Ù…ÙŠØ² Unicode Ø§Ù„Ù…Ø´ÙˆÙ‡"""
        # Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø´ÙˆÙ‡
        try:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø­Ø±Ù Unicode Ù…Ø´ÙˆÙ‡Ø©ØŒ Ø­Ø§ÙˆÙ„ Ø¥ØµÙ„Ø§Ø­Ù‡Ø§
            fixed = text.encode('utf-8', errors='ignore').decode('utf-8')
            
            # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…Ø´ÙˆÙ‡Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
            replacement_map = {
                'ïº®': 'Ø±', 'ïº ': 'Ø¬', 'ï»Ÿ': 'Ù„', 'Ø§': 'Ø§', 'ïº”': 'Ø©', 'ï¯¿': 'ÙŠ',
                'ï»¤': 'Ù…', 'ïº³': 'Ø³', 'ïº®': 'Ø±', 'ï»Ÿ': 'Ù„', 'Ø§': 'Ø§', 'ïº”': 'Ø©',
                'ïºª': 'Ø¯', 'ï¯¾': 'ÙŠ', 'â€“': '-', 'ïºª': 'Ø¯', 'ï»Œ': 'Ø¹', 'ï»Ÿ': 'Ù„',
                'Ø§': 'Ø§', 'Ù¡Ù¨': '18', ')': ')', 'ï»Š': 'Ø¹', 'ïº‘': 'Ø¨', 'ïº': 'Ø§',
                'ïº—': 'Øª', '(': '(', 'ï»“': 'Ù', 'ï»°': 'Ù‰', 'Ù£': '3', 'ï»®': 'Ùˆ',
                'ï¯¾': 'ÙŠ', 'ïº': 'Ø§', 'ï»£': 'Ù…', 'ïº”': 'Ø©', 'ï»¨': 'Ù†', 'ïº³': 'Ø³',
                'Ù¢': '2', 'Ù ': '0', 'Ù¢': '2', 'Ù¥': '5'
            }
            
            for wrong, correct in replacement_map.items():
                fixed = fixed.replace(wrong, correct)
            
            return fixed
        except Exception as e:
            logger.debug(f"ÙØ´Ù„ ÙÙŠ Ø¥ØµÙ„Ø§Ø­ Unicode: {e}")
            return text
    
    def _fix_known_patterns(self, text: str) -> str:
        """Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©"""
        fixed = text
        
        # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø´ÙˆÙ‡Ø© Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
        for correct_word, distorted_forms in self.arabic_patterns.items():
            for distorted in distorted_forms:
                fixed = fixed.replace(distorted, correct_word)
        
        return fixed
    
    def _fix_encoding(self, text: str) -> str:
        """Ù…Ø­Ø§ÙˆÙ„Ø© ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ±Ù…ÙŠØ²"""
        try:
            # ÙƒØ´Ù Ø§Ù„ØªØ±Ù…ÙŠØ²
            detected = chardet.detect(text.encode('utf-8'))
            encoding = detected.get('encoding', 'utf-8')
            confidence = detected.get('confidence', 0)
            
            if confidence > 0.7:
                fixed = text.encode(encoding, errors='ignore').decode('utf-8')
                return fixed
            else:
                return text
        except Exception:
            return text
    
    def _calculate_confidence(self, text: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© Ø£Ù† Ø§Ù„Ù†Øµ Ù…ØµØ­Ø­ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­"""
        if not text:
            return 0.0
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒÙ„Ù…Ø§Øª Ø¹Ø±Ø¨ÙŠØ© ØµØ­ÙŠØ­Ø©
        arabic_words = re.findall(r'[\u0600-\u06FF]{2,}', text)
        if not arabic_words:
            return 0.0
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        legal_terms = ['Ø§Ù„Ù…Ø§Ø¯Ø©', 'Ù…Ø§Ø¯Ø©', 'Ø§Ù„Ø¨Ø§Ø¨', 'Ø§Ù„ÙØµÙ„', 'Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†', 'Ø§Ù„Ø¹Ù…Ù„', 'Ø§Ù„Ø¹Ø§Ù…Ù„']
        found_terms = sum(1 for term in legal_terms if term in text)
        
        # Ù†Ø³Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©
        correct_ratio = found_terms / len(legal_terms) if legal_terms else 0
        
        # Ù†Ø³Ø¨Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        arabic_chars = re.findall(r'[\u0600-\u06FF]', text)
        arabic_ratio = len(arabic_chars) / len(text) if text else 0
        
        return (correct_ratio * 0.7) + (arabic_ratio * 0.3)

class FixedPDFProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ PDF Ù…Ø¹ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
    
    def __init__(self):
        self.fixer = ArabicTextFixer()
    
    def process_pdf_with_fixes(self, pdf_path: str) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© PDF Ù…Ø¹ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
        if not os.path.exists(pdf_path):
            return {"error": "Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"}
        
        try:
            doc = fitz.open(pdf_path)
            results = {
                "file_info": {
                    "path": pdf_path,
                    "pages": len(doc),
                    "producer": doc.metadata.get('producer', '')
                },
                "fixing_results": [],
                "extracted_articles": [],
                "statistics": {}
            }
            
            print(f"ğŸ”§ Ø¨Ø¯Ø¡ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù…Ù† {len(doc)} ØµÙØ­Ø©...")
            
            total_fixes = 0
            successful_fixes = 0
            
            for page_num in range(min(10, len(doc))):  # Ø£ÙˆÙ„ 10 ØµÙØ­Ø§Øª ÙÙ‚Ø· Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
                page = doc.load_page(page_num)
                original_text = page.get_text("text", sort=True)
                
                if not original_text or len(original_text.strip()) < 10:
                    continue
                
                print(f"\nğŸ“„ Ø§Ù„ØµÙØ­Ø© {page_num + 1}:")
                print(f"   Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {original_text[:100]}...")
                
                # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ
                fix_result = self.fixer.fix_arabic_text(original_text)
                
                results["fixing_results"].append({
                    "page": page_num + 1,
                    "original_preview": original_text[:200],
                    "fixed_preview": fix_result.fixed[:200] if fix_result.fixed else "",
                    "confidence": fix_result.confidence,
                    "method": fix_result.method
                })
                
                total_fixes += 1
                if fix_result.confidence > 0.3:  # Ø«Ù‚Ø© Ù…Ù‚Ø¨ÙˆÙ„Ø©
                    successful_fixes += 1
                    print(f"   âœ… Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­: {fix_result.fixed[:100]}...")
                    print(f"   ğŸ“Š Ø§Ù„Ø«Ù‚Ø©: {fix_result.confidence:.2f} - Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©: {fix_result.method}")
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¯ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­
                    articles = self._extract_articles_from_fixed_text(fix_result.fixed, page_num + 1)
                    results["extracted_articles"].extend(articles)
                else:
                    print(f"   âš ï¸  ÙØ´Ù„ Ø§Ù„Ø¥ØµÙ„Ø§Ø­ - Ø§Ù„Ø«Ù‚Ø©: {fix_result.confidence:.2f}")
            
            doc.close()
            
            # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            results["statistics"] = {
                "total_pages_processed": total_fixes,
                "successful_fixes": successful_fixes,
                "success_rate": successful_fixes / total_fixes if total_fixes > 0 else 0,
                "total_articles_found": len(results["extracted_articles"])
            }
            
            print(f"\nğŸ‰ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
            print(f"   - Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {total_fixes}")
            print(f"   - Ø§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {successful_fixes}")
            print(f"   - Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {results['statistics']['success_rate']:.2%}")
            print(f"   - Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {len(results['extracted_articles'])}")
            
            return results
            
        except Exception as e:
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"}
    
    def _extract_articles_from_fixed_text(self, text: str, page: int) -> List[Dict]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ§Ø¯ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­"""
        articles = []
        
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆØ§Ø¯ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥ØµÙ„Ø§Ø­
        article_patterns = [
            r'Ø§Ù„Ù…Ø§Ø¯Ø©\s*(\d+)[\s:\-]*(.*?)(?=Ø§Ù„Ù…Ø§Ø¯Ø©\s*\d+|$)',
            r'Ù…Ø§Ø¯Ø©\s*(\d+)[\s:\-]*(.*?)(?=Ù…Ø§Ø¯Ø©\s*\d+|$)',
            r'Ø§Ù„Ù…Ø§Ø¯Ø©\s*\((\d+)\)[\s:\-]*(.*?)(?=Ø§Ù„Ù…Ø§Ø¯Ø©\s*\(\d+\)|$)',
        ]
        
        for pattern in article_patterns:
            matches = re.finditer(pattern, text, re.DOTALL)
            for match in matches:
                if len(match.groups()) >= 2:
                    article_num = match.group(1)
                    content = match.group(2).strip()
                    
                    if len(content) > 10:
                        articles.append({
                            "page": page,
                            "number": article_num,
                            "content": content[:200] + "..." if len(content) > 200 else content,
                            "full_text": f"Ø§Ù„Ù…Ø§Ø¯Ø© {article_num}: {content}"
                        })
                        print(f"     ğŸ“– ÙˆØ¬Ø¯Øª Ø§Ù„Ù…Ø§Ø¯Ø© {article_num}")
        
        return articles

def test_arabic_fixing():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
    processor = FixedPDFProcessor()
    
    pdf_path = "backend/data/laws/labor_law.pdf"
    
    if not os.path.exists(pdf_path):
        print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {pdf_path}")
        return
    
    print("ğŸ”§ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ...")
    results = processor.process_pdf_with_fixes(pdf_path)
    
    if "error" in results:
        print(f"âŒ {results['error']}")
        return
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©
    print("\nğŸ“‹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©:")
    for fix_result in results.get("fixing_results", [])[:5]:  # Ø£ÙˆÙ„ 5 Ù†ØªØ§Ø¦Ø¬ ÙÙ‚Ø·
        print(f"\nğŸ“„ Ø§Ù„ØµÙØ­Ø© {fix_result['page']}:")
        print(f"   Ø§Ù„Ø«Ù‚Ø©: {fix_result['confidence']:.2f}")
        print(f"   Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©: {fix_result['method']}")
        print(f"   Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {fix_result['original_preview']}")
        print(f"   Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØµØ­Ø­: {fix_result['fixed_preview']}")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    articles = results.get("extracted_articles", [])
    if articles:
        print(f"\nğŸ“– Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ({len(articles)}):")
        for i, article in enumerate(articles[:10]):  # Ø£ÙˆÙ„ 10 Ù…ÙˆØ§Ø¯
            print(f"   {i+1}. Ø§Ù„Ù…Ø§Ø¯Ø© {article['number']} (Øµ {article['page']}): {article['content']}")
    else:
        print("\nâŒ Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙŠ Ù…ÙˆØ§Ø¯")
        
        # ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ÙØ´Ù„
        print("\nğŸ” ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ÙØ´Ù„:")
        print("   - Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù†Øµ Ù…Ø´ÙˆÙ‡Ø§Ù‹ Ø¨Ø´Ø¯Ø© ÙˆÙ„Ø§ ÙŠÙ…ÙƒÙ† Ø¥ØµÙ„Ø§Ø­Ù‡")
        print("   - Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ù„Ù Ù…Ù…Ø³ÙˆØ­Ø§Ù‹ Ø¶ÙˆØ¦ÙŠØ§Ù‹ (ØµÙˆØ±Ø©)")
        print("   - Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ OCR Ù…ØªØ®ØµØµ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©")
    
    return results

if __name__ == "__main__":
    test_arabic_fixing()