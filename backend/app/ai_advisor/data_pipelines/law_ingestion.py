import logging
import asyncio
import os
import sys
from typing import Set, Dict, Any, List, Tuple
from pathlib import Path

# --- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª (Ù…Ù‡Ù… Ù„Ù„ØªØ´ØºÙŠÙ„ ÙƒØ³ÙƒØ±ÙŠØ¨Øª) ---
current_dir = Path(__file__).resolve().parent
backend_dir = current_dir.parent.parent.parent 
sys.path.insert(0, str(backend_dir))

from app.ai_advisor.rag.semantic_retriever import SemanticRetriever
from app.ai_advisor.rag.pgvector_manager import PgVectorManager
from app.ai_advisor.rag.advanced_pdf_processor import AdvancedPDFProcessor  # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù‡Ø°Ø§

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# âš ï¸ Ø¶Ø¨Ø· Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡
os.environ['AI_DATABASE_URL'] = 'postgresql+asyncpg://postgres:123456@localhost:5432/legal_ai'
AI_DATABASE_URL = os.getenv("AI_DATABASE_URL")

if not AI_DATABASE_URL:
    logger.error("âŒ Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© AI_DATABASE_URL ØºÙŠØ± Ù…ÙØ¹Ø¯.")
    sys.exit(1)

# Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
DATA_ROOT = backend_dir / "data"

COUNTRIES = [
    "egypt", "saudi_arabia", "uae", "jordan", "lebanon", "syria", "iraq",
    "qatar", "kuwait", "bahrain", "oman", "yemen", "palestine", "libya", 
    "tunisia", "algeria", "morocco", "mauritania", "sudan", "somalia",
    "djibouti", "comoros"
]

DOCUMENT_CATEGORIES = {
    "01_constitutions": "constitution",
    "02_decisions": "decision", 
    "03_reports": "report",
    "04_laws": "law",
    "05_judgments": "judgment",
    "06_international_agreements": "international_agreement",
    "07_legal_templates": "legal_template"
}

# Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
SUPPORTED_FILE_TYPES = {
    '.pdf', '.txt', '.md', '.docx', '.doc', 
    '.jpg', '.jpeg', '.png', '.tiff', '.bmp'
}

class LawIngestionPipeline:
    """Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ø¨ØªÙ„Ø§Ø¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
    
    def __init__(self, database_url: str):
        self.database_url = database_url
        self.retriever = None
        self.pdf_processor = AdvancedPDFProcessor()
        
    async def initialize(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª"""
        logger.info("ğŸ”— Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        self.retriever = SemanticRetriever(database_url=self.database_url)
        await self.retriever.initialize()
        logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ø¨Ù†Ø¬Ø§Ø­")
    
    async def get_processed_files(self) -> Set[str]:
        """Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹"""
        logger.info("Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹...")
        processed_files = set()
        try:
            async with self.retriever.vector_db.pool.acquire() as conn:
                rows = await conn.fetch("SELECT file_path FROM ai_legal_documents WHERE file_path IS NOT NULL")
                for row in rows:
                    processed_files.add(str(Path(row['file_path']).resolve()))
            logger.info(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(processed_files)} Ù…Ù„Ù ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡.")
            return processed_files
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
            return processed_files

    async def find_all_files(self) -> List[Tuple[Path, str, str]]:
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª"""
        files_to_process = []
        
        for country in COUNTRIES:
            country_path = DATA_ROOT / "countries" / country
            
            if not country_path.exists():
                logger.debug(f"Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¯ÙˆÙ„Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {country_path}")
                continue
                
            for category_folder, doc_type in DOCUMENT_CATEGORIES.items():
                category_path = country_path / category_folder
                
                if not category_path.exists():
                    logger.debug(f"Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {category_path}")
                    continue
                    
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯
                for file_type in SUPPORTED_FILE_TYPES:
                    for file_path in category_path.rglob(f"*{file_type}"):
                        files_to_process.append((file_path, doc_type, country))
                    
        return files_to_process

    async def process_file(self, file_path: Path, doc_type: str, country: str) -> bool:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ÙØ±Ø¯ÙŠ"""
        try:
            logger.info(f"--- Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø©: {file_path.name} (Ø§Ù„Ø¨Ù„Ø¯: {country}, Ø§Ù„Ù†ÙˆØ¹: {doc_type}) ---")
            
            # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            metadata = {
                "title": file_path.stem,
                "file_path": str(file_path.resolve()),
                "file_size": file_path.stat().st_size,
                "document_type": doc_type,
                "country": country,
                "source_folder": file_path.parent.name,
                "file_extension": file_path.suffix.lower()
            }

            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø§Ø¨ØªÙ„Ø§Ø¹
            result = await self.retriever.ingest_legal_document(
                pdf_path=str(file_path),
                metadata=metadata
            )
            
            if result.get("success"):
                logger.info(f"âœ… ØªÙ… Ø§Ø¨ØªÙ„Ø§Ø¹ {file_path.name} Ø¨Ù†Ø¬Ø§Ø­.")
                logger.info(f"   (ID: {result.get('document_id')}, Ø§Ù„Ù…ÙˆØ§Ø¯: {result.get('articles_processed')}, Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡: {result.get('chunks_created')})")
                return True
            else:
                logger.error(f"âŒ ÙØ´Ù„ Ø§Ø¨ØªÙ„Ø§Ø¹ {file_path.name}: {result.get('error')}")
                return False

        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙƒØ§Ø±Ø«ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© {file_path.name}: {e}", exc_info=True)
            return False

    async def run_pipeline(self):
        """ØªØ´ØºÙŠÙ„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø®Ø· Ø£Ù†Ø§Ø¨ÙŠØ¨ Ø§Ø¨ØªÙ„Ø§Ø¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª...")
        
        # 1. ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
        await self.initialize()

        # 2. Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        processed_files = await self.get_processed_files()

        # 3. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¬Ø¯ÙŠØ¯Ø©
        logger.info(f"Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ: {DATA_ROOT}")
        all_files = await self.find_all_files()
        
        files_to_process = []
        for file_path, doc_type, country in all_files:
            resolved_path_str = str(file_path.resolve())
            if resolved_path_str not in processed_files:
                files_to_process.append((file_path, doc_type, country))
            else:
                logger.debug(f"ØªØ®Ø·ÙŠ Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯: {file_path.name}")

        if not files_to_process:
            logger.info("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©. Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø­Ø¯Ø«.")
            return

        logger.info(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(files_to_process)} Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...")

        # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        successful_ingests = 0
        failed_ingests = 0

        for file_path, doc_type, country in files_to_process:
            success = await self.process_file(file_path, doc_type, country)
            if success:
                successful_ingests += 1
            else:
                failed_ingests += 1
            logger.info("--- Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù ---")

        logger.info("ğŸ Ø§ÙƒØªÙ…Ù„ Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨.")
        logger.info(f"Ù…Ù„Ø®Øµ: {successful_ingests} Ù†Ø¬Ø§Ø­ØŒ {failed_ingests} ÙØ´Ù„.")

async def main():
    """Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    pipeline = LawIngestionPipeline(database_url=AI_DATABASE_URL)
    await pipeline.run_pipeline()

if __name__ == "__main__":
    asyncio.run(main())